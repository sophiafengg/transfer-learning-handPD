{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29372d5b-de35-4aa6-abeb-6480e1d8d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc481e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4e936-0001-4383-b2b3-4e2bb8adb043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either Meander or Spiral to use,\n",
    "# or you can train a mixed model if uncomment all\n",
    "flds = [#'Meander_HandPD/Meander_Control',\n",
    "        #'Meander_HandPD/Meander_Patients',\n",
    "        'Spiral_HandPD/Spiral_Control',\n",
    "        'Spiral_HandPD/Spiral_Patients']\n",
    "\n",
    "images=[]\n",
    "labels=[]\n",
    "exams = []\n",
    "img_files = []\n",
    "for f in flds:\n",
    "    img_list = glob.glob(f+'/*.jpg')\n",
    "    if f.split('_')[-1] == 'Control':\n",
    "        labels += [0]*len(img_list)\n",
    "    else:\n",
    "        labels += [1]*len(img_list)\n",
    "    for im in img_list:\n",
    "        images.append(Image.open(im).convert(\"RGB\"))\n",
    "        exams.append(im.split('/')[-1].split('-')[0])\n",
    "        img_files.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410b6b7-ed0f-40e2-b1f0-baa24082013b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a9a05-1914-4130-afff-e2bc8521f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, images, labels, transform, exams=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.exams = exams\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        tensor_image = self.transform(image)\n",
    "        if self.exams:\n",
    "            return tensor_image, label, self.exams[idx]\n",
    "        else:\n",
    "            return tensor_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ead0c-42ad-4f92-b9c3-4a71e76270a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "dataset = DataSet(images, labels, transform, exams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3347890-a3fd-4f4d-ba07-03db34b6bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"Model saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744546d-f8c3-437f-96dd-475e59b5b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8)\n",
    "\n",
    "# Load ResNet50 model WITH pre-trained parameters,\n",
    "model = models.resnet50(pretrained=True)\n",
    "# Freeze the mdoel parameters learned from large general image dataset\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "#Add simple MLP layers whose parameters will be learned from our HandPD data\n",
    "n_feats = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "               nn.Linear(n_feats, 128),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(128, 2)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d6b32-7e07-49b2-9895-ff03bf3e715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloaders, model, criterion, optimizer, num_epochs=20):\n",
    "    best_model = model\n",
    "    best_val_loss = 1000000\n",
    "    test_acc = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            npreds = 0.0\n",
    "            val_loss = 0.0\n",
    "            for inputs, targets, exams in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == targets.data)\n",
    "                npreds += len(preds)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_acc = running_corrects.double() / npreds\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "            if phase == 'val':\n",
    "                val_loss = epoch_loss\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model = model\n",
    "                    print('Set best model.')\n",
    "\n",
    "    for phase in ['test']:\n",
    "        best_model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        npreds = 0.0\n",
    "        all_preds = []\n",
    "        all_outputs = []\n",
    "        for inputs, targets, exams in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = best_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == targets.data)\n",
    "            npreds += len(preds)\n",
    "            all_preds.append(preds)\n",
    "            all_outputs.append(outputs.detach().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase])\n",
    "        epoch_acc = running_corrects.double() / npreds\n",
    "        test_acc = epoch_acc\n",
    "        print('+++++++++++ Test {} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                    epoch_loss,\n",
    "                                                    epoch_acc))\n",
    "        all_outputs = np.vstack(all_outputs)\n",
    "    return (best_model, all_preds, all_outputs, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648abfc-1715-4bbe-b051-7866a16fce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Stratified K-Fold cross-validator\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "k_folds = 5\n",
    "skf = StratifiedGroupKFold(n_splits=k_folds, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0ef2d-b12e-45c3-877e-727987505123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Cross-validation process\n",
    "best_model = model\n",
    "results = []\n",
    "test_outputs = []\n",
    "test_ids = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for fold, (train_val_idx, test_idx) in enumerate(skf.split(np.zeros(len(labels)), labels, exams)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "\n",
    "    split_train_val = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, val_idx = next(split_train_val.split(np.zeros(len(train_val_idx)), [labels[i] for i in train_val_idx]))\n",
    "\n",
    "    # Subset datasets\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    test_subset = Subset(dataset, test_idx)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=8, shuffle=False)\n",
    "    test_loader = DataLoader(test_subset, batch_size=8, shuffle=False)\n",
    "\n",
    "    dataloaders = {'train':train_loader,'val':val_loader, 'test':test_loader}\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    best_model, all_preds, all_outputs, fold_test_acc = train_model(dataloaders, model, criterion, optimizer, num_epochs=80)\n",
    "\n",
    "    test_outputs.append(all_outputs)\n",
    "    test_ids += test_idx.tolist()\n",
    "\n",
    "    #save_model(best_model,f'models/ResNet_handPD_cv_by_EXAM_fold_{fold + 1}.pth')\n",
    "    results.append(fold_test_acc)\n",
    "\n",
    "test_outputs = np.vstack(test_outputs)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "test_outputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b1a0c-74b8-46e9-b0e0-3017f3f79517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_imgs =[img_files[i] for i in test_ids]\n",
    "test_labels =[labels[i] for i in test_ids]\n",
    "\n",
    "detailed_result_df = pd.DataFrame(data=test_ids, columns=['test_idx'])\n",
    "detailed_result_df['healthy_prob'] = test_outputs[:,0]\n",
    "detailed_result_df['patient_prob'] = test_outputs[:,1]\n",
    "detailed_result_df['image_path'] = test_imgs\n",
    "detailed_result_df['label'] = test_labels\n",
    "\n",
    "detailed_result_df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d7fc1-ad0f-4938-b0fb-61ef8803f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array([r.tolist() for r in results]).mean())\n",
    "print(np.array([r.tolist() for r in results]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ec487-3973-4ad3-8a3f-bbda217b308f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "838e7165-1ecf-4bbd-ba17-602f387fdd17",
   "metadata": {},
   "source": [
    "#Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f2fee-0bdb-4ef1-bc47-7d758b4eb168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48274b-7f2b-416d-ad06-ef3a28c2063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [\n",
    "    # 'Meander_HandPD/Meander_Patients/0213-8.jpg',\n",
    "    # 'Meander_HandPD/Meander_Patients/0187-6.jpg',\n",
    "    'Spiral_HandPD/Spiral_Patients/0197-2.jpg',\n",
    "    'Spiral_HandPD/Spiral_Patients/0246-3.jpg',\n",
    "]\n",
    "\n",
    "for img_path in img_paths:\n",
    "    img_name = img_path.split('/')[-1].split('.')[0]\n",
    "    rgb_img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    img = np.array(rgb_img, dtype=np.uint8)\n",
    "\n",
    "    cv_img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    infer_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224,224)),\n",
    "            normalize\n",
    "        ])\n",
    "    \n",
    "    img_tensor = infer_transform(img)\n",
    "    input_tensor = torch.unsqueeze(img_tensor, dim=0)\n",
    "    \n",
    "    target_layers = [best_model.layer1[0], best_model.layer1[-1],\n",
    "                     best_model.layer2[0], best_model.layer2[-1],\n",
    "                     best_model.layer3[0], best_model.layer3[-1],\n",
    "                     best_model.layer4[0], best_model.layer4[-1],\n",
    "                    ]\n",
    "\n",
    "    # We have to specify the target we want to generate the CAM for.\n",
    "    targets = [ClassifierOutputTarget(1)]\n",
    "\n",
    "    for ti in range(len(target_layers)):\n",
    "        tlayers=[target_layers[ti]]\n",
    "    \n",
    "        # Construct the CAM object once, and then re-use it on many images.\n",
    "        with AblationCAM(model=best_model, target_layers=tlayers) as cam:\n",
    "          # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "          grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    \n",
    "          grayscale_cam = grayscale_cam[0, :]\n",
    "          visualization = show_cam_on_image(np.float32(img_tensor.permute(1,2,0)) / 255, grayscale_cam, use_rgb=True)\n",
    "          # model_outputs = cam.outputs\n",
    "          cam_image = cv2.cvtColor( visualization, cv2.COLOR_RGB2BGR)\n",
    "          cv_img2 = cv2.cvtColor( cv_img, cv2.COLOR_BGR2RGB)\n",
    "          im_h = cv2.hconcat([cv_img2, visualization, cam_image])\n",
    "          #im_h = cv2.hconcat([img, visualization, cam_image])\n",
    "    \n",
    "          cv2.imwrite(f'results/{img_name}_layerid_{ti+1}.jpg', im_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8aff9f-5e4d-46a2-8455-61434f2409fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_env_p312",
   "language": "python",
   "name": "neuro_env_p312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
